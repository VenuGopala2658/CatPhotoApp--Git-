{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6xySYoXDi9KpqdEvMO5KC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenuGopala2658/CatPhotoApp--Git-/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DQ9bro3l9xS",
        "outputId": "c99a47cd-7943-49e5-fe28-e851523b5563",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq8rokGPmCc7",
        "outputId": "f8ed9a86-15c2-45f5-ad48-ece926c4542e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "Drones_Birds_path = '/content/Drone_Or_Bird.zip'\n",
        "\n",
        "Drones_Birds_folder_path = '/content/Drones_Birds_dataset'\n",
        "\n",
        "with zipfile.ZipFile(Drones_Birds_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(Drones_Birds_folder_path)\n",
        "\n",
        "Drones_Birds_files = os.listdir(Drones_Birds_folder_path)\n",
        "print(\"Extracted files:\", Drones_Birds_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs9sfBsImaTj",
        "outputId": "c38b91be-af8c-44b8-a569-1ee91251f8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['Drone_Or_Bird']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Drones_And_Birds_path = os.path.join(Drones_Birds_folder_path, 'Drone_Or_Bird')\n",
        "Drones_And_Birds_files = os.listdir(Drones_And_Birds_path)\n",
        "\n",
        "print(\"Contents of 'bone_fracture' folder:\",Drones_And_Birds_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLBnd3h2fsBC",
        "outputId": "2c7f1766-2dcb-479b-af05-3d613bd3b364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'bone_fracture' folder: ['Train', 'Test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Drones_And_Birds = os.path.join(Drones_And_Birds_path, 'drones')\n",
        "test_Drones_And_Birds = os.path.join(Drones_And_Birds_path, 'birds')\n",
        "\n",
        "train_DABfiles = os.listdir(train_Drones_And_Birds)\n",
        "test_DABfiles = os.listdir(test_Drones_And_Birds)\n",
        "\n",
        "print(\"Training files:\", train_DABfiles)\n",
        "print(\"Testing files:\", test_DABfiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f88jpz9fvBn",
        "outputId": "bd8d8a8c-d0b0-45af-c3f5-517d5960fa9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['fd660a1b-5362-4e57-b281-f78771cc5c63.jpg', '0eeb3e6b-9818-49ff-b76f-acbd2d443fa6.jpg', 'a45d86cb-c478-4dec-984d-061adfccde4c.jpg', 'ebf611ea-45db-4778-b031-0c4a312105c3.jpg', '0f9b27ce-40f7-4a38-b329-86e0f62a8a95.jpg', 'f072177b-e55f-4d0d-b6d5-9489feb52d4a.jpg', '9458480e-48e7-4d25-a53c-c1638acf4c3f.jpg', 'c7a75f37-3cf3-4526-a8af-6961b7f3f0fd.jpg', '71826869-8385-45f9-8b42-4a54c614c3b5.jpg', '565e4ba0-3f52-4490-b937-f4f3789512f9.jpgupdated201605201717imageversionFacebookexactH630exactW1200exactfitcropnoborder', '993681c8-b017-4d11-9dca-aaba97e19955.jpg', '42425985-c7a9-436c-9f80-760dc9dbfe18.jpeg', 'df31167f-263e-4113-a365-2883c34c039c.jpg', 'dd0b0b16-ef21-4c11-b2d2-986f4ef1a622.jpg', '202036d2-af55-4a10-844d-89fc7a575730.jpg', '1bfe7020-7aed-4e34-a2b3-72bc185e843b.jpg', 'd27da3b6-269c-4dad-bd2d-13e267e897cf.jpg', 'ce051209-66b2-473d-8347-222a1dc16c76.jpg', '470ec2a1-0179-40de-8574-d09734df989f.jpg', '2fe4681a-a92d-4a5a-8d45-9f79cae9861e.jpg', '3a96ece1-537c-4890-b98b-a884d0b096b0.jpg', '099703dd-0294-471f-96de-ebf871937906.jpg', 'bf4c5f97-d3bc-4290-adec-e55b4ef0e298.jpg', 'f60353e3-6cce-4ffa-8c59-b8ccc4886130.jpg', '703decd0-9cdb-4187-84d9-aa24702486a9.jpg', 'f9914802-1499-4fd0-a43c-7eb94b158836.jpg', 'c917ba9f-496f-449c-a2e3-0781cbfd8f0b.jpg', 'b36f2943-7ead-4472-942f-0436529fc4c4.jpeg', 'fb534322-57e9-4f9c-8b17-4def9622e05f.jpg', '2e5c027a-68b0-452a-9e42-56e3bcfa1259.jpg', 'ae4c12a4-2b60-404e-8822-a9dad0fc1dfb.jpg', '65996eab-2a44-4760-b7db-50398ea9791d.jpg', '0ce60dde-ed13-4fd3-85b9-0a824e51676c.jpg', 'ee3ac2eb-8f97-4264-b869-2142ada758e4.jpg', '0dbf5fed-e6cd-4e0e-919c-72abeb6ff2e1.jpg', 'bb36682f-4bc1-4dcf-813e-f1ee14b1cf7f.jpg', 'ffc25b22-1c0f-4952-9e12-ee117cb3d09d.jpg', 'cf5de35a-9d2f-45bf-8935-e03bb18d741f.jpg', 'f6c3f42c-5095-4cc9-8128-5d2cdeb5e870.jpg', 'c0482e08-798c-493c-a23e-c1e792bb4a48.jpg', 'a0e17740-a126-44f2-adfd-4876974d1934.jpg', 'c978c190-463b-49af-bd61-c63c5ad19c14.jpg', '991407df-d9c4-4891-867f-04a41a47c848.jpg', 'e4a0ed61-ee8b-4020-8038-410b9e88722f.jpg', 'd228e6ea-fffb-480d-bb04-1d29961c9648.jpg', '665c1c53-1328-43cc-97f3-a4f0e81a4ec5.jpg', 'cd4f1973-2616-403b-b61d-93f7423ce8e8.jpg', 'bd7cd86b-b681-4c16-b116-47c08b9274dd.jpg', 'fae177b1-b184-445d-b965-23e607399fae.png', 'd1a78686-213d-4435-817e-6fa65b851981.png', 'bc7ada80-4161-4395-a107-78bd376282c1.jpg', 'e17c99fc-70fb-428a-a95c-a6887eb52ea9.jpg', 'c6f4657d-a767-4168-84fa-4e2960f15bfc.jpg', '0ff3da67-09bd-41e0-87d1-2d665ea00208.png', 'fc81b00c-048f-432e-9251-517586852c3e.jpg', 'dd02d817-6040-4668-89dd-f9a2a307216d.jpg', '253696fc-94ab-40a8-b77d-9549ff839216.jpg', 'e7528219-42bf-498b-a277-3d38b58e58e3.jpg', 'a25c1458-2bb6-4444-9fef-0da55f1f6e7f.jpg', '6dd7c5c0-8982-41cd-8205-522b53910a5e.gif', 'fccd1ca4-a63c-469e-813d-85a912f516ef.png', 'f0939d8f-b1e5-4448-9fa7-4efcc2a8981b.jpg', '0f54face-8758-4f3b-8231-443bf085a94c.jpg', '92305393-af49-491e-9b48-7b038340a4b7.jpg', 'd72a6b08-bdb3-417b-a524-5842178877b5.jpg', 'ddfa8041-c562-41b8-8700-cdc11f0cb4c3.jpg', '50652a6e-f308-492b-b3e3-d55f1e57637b.jpg', '1f25afbe-58a5-4627-919b-fc171b920e24.jpg', '1e3fa0c9-8eda-474e-95b2-e70558f74d4e.jpg', 'bd658de4-599d-4d59-be88-59af608f83c0.jpg', '0691d67b-0e62-4e74-a7c7-bef9924d083a.jpg', '34019870-235f-446d-a10c-11e00be504b1.jpg', 'f3617a75-d433-4cb4-b8b5-31150411cfa7.jpg', 'c5bca0d7-94b3-42f9-80e7-69822bff2c98.jpg', '62866ecc-1ea3-4f20-bbb5-4cd6837001f8.jpg', 'df1df129-e166-405f-9bf8-247257391a16.jpeg', '600eb4ea-740f-4d5e-9de9-a2f6a5f5a6c9.jpg', '1b462dac-09b5-4ccf-a001-a935c23d06cb.jpg', '37452103-9786-4f63-a6ac-64bd46044d7c.jpg', 'f64005c8-4e8a-444d-9318-73acfbe2fa0f.jpg', '3475059c-99dd-4692-9816-6cbfba9c1f17.jpg', 'eedfa861-d7f3-44d0-8117-9a6037c0000c.jpg', '02f16ac8-d7fe-4cf0-96db-5cb940bbe887.jpg', '1bddb405-632c-4881-a80d-5fe78f476737.jpg', '22923177-9130-4e69-942a-59f0a649adcc.jpg', '539dbba3-2281-4383-804e-8caff40e13b6.jpg', 'e58b3de3-c147-4b73-833a-3a8f99e8d82b.jpg', 'a1294f17-94dd-4c78-a7f9-cd8086227c73.jpg', '0e1676df-c3e9-44de-aa4a-1e28d23bde13.jpg', '692a442c-4394-44be-8302-5bed57ad457f.jpg', 'cd0aa537-b032-46d2-a110-6c1548bff5a4.jpg', 'af315f2a-7284-4afb-babd-a81cea0e8d11.jpg', '2ddf8e9a-5c04-4a66-98eb-9fb73d4b130f.jpg', 'db81ca1c-d9b2-43e2-9b17-42b9ebbc2795.jpg', 'cfb6d952-8d6a-41c8-9b32-412b5f914018.jpg', 'aef5a535-4170-4752-bdfa-07da5f32430f.jpg', 'a461bb93-1577-4663-a5c4-5652b91b14ac.jpg', '0375f047-313c-440b-a6c2-9b82a209547d.jpg', '27679331-6a42-484f-869f-e5e9965f9d0b.jpg', 'df543bdd-b483-4ee4-a0f0-aed44d31fafd.jpg', '7713239a-50f6-4e4c-9cdb-2144a067d4b4.jpg', 'f4ffc10f-426e-443a-95db-7d4280035efe.jpg', 'a2e1205e-5ed5-46f1-8ffb-63f1969e98c1.jpg', 'd40c2067-03e5-4116-a252-dcc2623c606f.jpg', 'a16892c3-c237-4acf-ad9d-3d7c8a94a49e.jpg', 'a75af03e-a1f4-484f-a44c-ddea9e5186c4.jpg', 'c0eacb5e-7e9a-48de-ab4e-af7d7f916a61.jpg', '329ffc5b-04ea-4418-aba4-afd55e435b0d.jpg', 'a3240e0a-4132-46a8-9e34-3dd722229703.jpg', '2b977f7b-e79b-4ffb-97ff-1c6bd35adf00.jpg', '1c5bb3a9-21d1-4234-abb1-e284f070d67e.png', 'b6a01ab8-5e12-4397-8965-cd50ec937650.jpg', 'e5ed9253-3142-4bc7-8ee3-5e6c8b0e8e45.png', '06d6c3f4-f655-4d0f-b18a-a4ae78f5983f.jpg', 'da0864d8-3ea1-4494-a76e-8db4ec2af71a.jpeg', 'f6bb3595-ce46-4c88-997b-c0f7f1797b84.jpg', 'db950a8d-dfcf-49ba-978a-67035b8b842b.jpg', 'd6c39ef3-7d18-4744-8146-71a2865b0c36.jpg', 'c617f8ac-74db-41a4-8bc1-aace9601f01f.jpg', '0e3dcfd8-9162-43e3-aeeb-ef7b03ddf304.jpg', 'eb6f76d0-b5eb-4f73-a6d2-9e668d392faf.jpg', '9680900c-de20-4dcb-b761-3fc45172b10e.jpg', '82050651-91da-4f2d-992d-ac68e6078731.jpg', 'd7fb940c-e421-4a1f-97b0-faf324331cb7.jpg', '540bad82-4b8a-46a7-8ce6-681d4fd38399.jpg', '531e9b13-4528-4cc3-a7d9-ff2c89075b53.jpg', '5660208d-3728-4cc1-b8c2-fa571d822126.jpg', 'b82a62a0-e00e-4060-ad53-4cdfe13b0eee.bmp', 'cdfb0e09-62d3-4da8-90cd-2129b3a11d37.JPG', 'bef22d2c-2d17-4e0f-8a07-bf451426bff2.jpg', '2ff83b8e-0c85-4519-9b8a-e2ce33d8abec.jpg', 'bc3e592d-5fcd-4e0b-9f0b-ed13018e2a8d.jpg', 'cd4e5ef2-c64a-462a-a0ee-c6c0a6d42bd5.bmp', 'e49598c5-faf9-480c-8be5-eae268674c33.jpeg', '0dd388ec-0aea-420f-a2e8-b88752991475.jpg', '108759dc-ad0c-4df0-95cf-818b30c30970.jpg', 'edb7ed01-e88f-44c8-9655-a6ece0424ab8.png', 'ef80a820-7e99-4efa-8d1e-4d61da59ec0e.jpeg', '410067dd-25a1-451e-aa01-dad93daf0a17.jpg', '1efe6d9f-dd1c-4429-be1d-9260769e1f3b.jpeg', 'e4bb86e0-7db0-443c-b5bd-2fb711d6a396.jpg', 'ec1f1f15-96be-466a-8004-31ada86da743.jpg', '27988a77-56a0-4cce-9af8-dde7c5772fc7.jpg', 'cf43c64a-503d-4005-aa31-48c6fa423f2c.jpg', 'a3b8d577-b6ef-400f-a3ba-057549da528a.jpg', 'd1a025f7-2afb-4f6a-a501-0df63e524d10.jpg', 'a553bd72-5e9f-4232-8ef5-59a95f225359.jpg', 'e14ba81b-a9ac-4c69-8c7b-8661ec02f873.jpg', '1d843c8d-5c7d-469b-a0e1-b31802a34eba.jpg', '80114510-c1f8-47ac-b568-d0aaf0908a94.JPG', 'd4a7a433-f25c-4637-9c9b-f75c63fd6f11.jpg', 'a565ba39-a3a6-44fb-b055-9ec37d2b1bb1.jpg', 'd7330acc-5832-4b8d-9c8f-0030896036c2.jpg', 'a8e83d7a-6071-479c-bc25-9320f6ad1316.png', '455739cf-4357-4098-9783-652871f88b37.jpg', 'caefaea3-aaab-438b-89e5-bf4accde0ac9.jpg', 'c89b265e-8bf8-44a2-9df8-56069716d76f.jpg', 'd112bc6f-6c66-4d57-9dbb-667213976256.jpg', '07aadf09-547b-47c6-bc9b-46189ac4bd4c.jpg', 'c575f265-cec4-4e5e-8eba-5614fc749ed1.jpg', '329b8da7-6e60-441d-81fc-eac9118cd239.gif', 'a5ef3933-0dcd-4edb-8061-3aa10264237b.jpg', 'd77e3361-9363-421b-8bd9-77806d8f5f06.jpg', '1e9f33d0-7300-42bc-9bd6-326e9f07e59f.jpg', 'b90466aa-5560-41ef-b345-00fad35af751.jpeg']\n",
            "Testing files: ['e9188796-d823-47c1-8007-75946116ea1e.jpg', 'd3089f83-ab93-4092-ba55-2a29ec4bff53.JPG', 'e498c87f-666e-483a-8d16-ebdbde850e7e.jpg', '5532e833-e127-4e48-96db-9fa315d15c64.jpg', '6915aff8-ce5c-4e38-b401-237cefaa6ce7.png', 'b70bd575-c88e-4623-87b1-50ef8e065de8.jpg', 'b2f06b58-6884-4b69-9d58-74c3df7fdd21.jpg', 'c4c7281f-02f6-476e-afa7-b3baddde3389.jpg', 'c0ebd711-4bd5-4605-be9e-8f6c8802a5d1.jpg', '0adf7f21-6068-47f0-84f0-c464f855a85d.jpg', '4540c21a-c93c-4ed3-bf7a-2ba51fb0a756.jpg', 'a9ea09f3-5c1a-4497-a68f-437af324c5d0.png', '34d13c1f-e29e-497e-84bd-ac1c897bfa7d.jpg', '134c2745-d42c-4e24-bb4f-3738f79de8ae.jpg', 'd6096bea-4369-4b1f-84fd-d09ab245f694.jpg', '0e4aaa7a-92ab-4d96-9a4f-b73f89a44af5.jpg', 'f3e96d48-5ab7-4d6d-a230-dadee102919c.jpg', '5120b845-b69a-4c1a-9094-5b27144507dc.gif', '9971e9a9-8f9b-4195-821a-0864d9ff008c.jpg', 'fe2f4c22-dc13-43b7-af9a-ed2c901f32b6.jpg', 'e458c1b2-4c80-4a42-b28f-5927bffa507f.png', 'b4f75094-47d7-41e5-8df2-81be896a82bd.jpg', '9329b9d4-e34e-40cf-a4d7-f7880c0ffc38.jpg', '6461fdf2-03fb-4a94-9059-0bae4a4f23a0.jpg', '10c0c502-724e-41d6-95e6-fc80ae3b37c6.jpg', '808b86b2-1b47-4493-9ab8-166d86109ac7.jpg', 'ca5657fc-f615-4153-bc6a-771b0f3344ed.jpg', 'f0cb4e67-c10a-4c36-9b14-73aae7c54d4a.jpg', 'bbea4dd5-01a2-435c-8e7a-523e8109f392.jpg', '0a5b4074-52c7-42d5-8b5e-54b4f93fc129.jpg', '0bf9f08a-2693-42e6-ab35-9f08f97e4603.jpg', '08863cbd-4a84-46ae-a5f5-920579de1b6f.png', 'c2f47e10-f4b7-40ff-b81a-580470f89378.jpg', '79d12826-52ff-4528-906d-b8b5c5447ffa.jpg', '4a9112e6-ca59-437b-bc43-6d18ad571a7f.jpg', '4689c884-ed90-43ea-84de-254f8d633f16.jpg', 'b94c7360-bded-4775-8047-5f1daa569c9d.jpg', '2b6f9be8-c93c-4260-9e2c-9fb2036c6493.jpg', '3e3069cf-4dcd-4c15-beb6-a63e2264e2d8.jpg', '44bbf407-7e00-4403-be0a-c3f1270fe98f.jpg', '30dd033c-90a3-4083-a969-3d6e077e47c8.jpg', 'aebd7ed5-b62b-469a-a754-76dd24d1e6a6.jpg', 'a67634ef-da17-459d-942f-ac6e8f3badbb.jpg', 'c90c58c2-cdcb-4656-8a44-2f27a46d7e21.jpg', '91a3f3e7-7625-44bb-a969-9a79bc30a159.jpg', '84ac73c2-727c-400e-a3c3-1243669e66fa.jpg', '8db30af7-ca36-4a6e-b7ae-b23c335e4df2.jpeg', 'f37fdf21-2fc7-479f-b2cf-ce1a0e95a222.jpg', 'a89264b9-02b4-41cf-8d7f-6f7ddef77cde.jpeg', 'a336c0fd-6bcc-44e3-affa-418edbddc287.jpg', '8f173a2b-5bd4-4f7c-8d48-38008fda125c.jpg', '2829a581-b5de-4161-bf1b-b6d9b78b6a94.jpg', 'a9c44bf8-c15e-4f3e-9371-7f5ba79551e9.jpg', 'ff605692-ab22-4223-a6ab-a047c9f7976a.jpg', 'e44b5602-9218-4789-8bfc-3907bf507bbb.jpg', '9c239e8a-aad7-42c4-bbc8-ef06e4e660a6.jpeg', '5566456b-9dbe-47fe-b41d-6ed59f33f988.jpg', 'c9d28535-682f-4caa-8d13-4fff1fdc1208.jpg', 'cda3bbe2-83f0-4884-b155-848b89d6349a.jpg', '5460e6f1-c2c2-4b1d-bf25-18666f486d00.jpg', 'fee75851-cbc5-4063-952f-e341e55dc98a.jpeg', '2eab572e-665a-42a9-9a63-f819b834a755.jpg', '050a45d2-e917-442f-9979-53f9017a8538.jpg', 'aa0a9a48-1a55-4cc3-a3f9-82e72602efef.jpg', '145c9486-5884-41b2-a391-ed692360a50b.jpg', '0c251caa-9ed5-4f35-bdaa-a632584c8be7.jpg', 'fe3580e9-91bb-406f-ad72-a689c6d31e0c.png', 'fdc4966a-559b-4e93-9c56-98b86dacdc0d.jpg', '7e1d9204-9294-459a-b688-34ab894819ac.jpg', '74e686a9-a92c-4ff2-a0bb-9573916f267a.jpg', '56ce4aab-3d02-4749-b872-1d31bfd8b476.jpg', 'cb5aa262-b03a-4e07-82a7-ea7bfcdb84f5.jpg', '15b61826-3ea0-407d-8be8-7e97fbf260a2.jpeg', 'c6851fde-6268-477b-ad27-96ab44ef917a.jpg', 'a685ee3f-252d-4309-ade3-68a10c35b656.jpg', '1e68db20-be3f-49b3-862f-6b91730c1a5b.jpg', '775c6102-8c42-407c-9e5a-95a4a496e9f1.jpg', '5083960f-20da-434e-a3e8-9858a2e0d2e6.jpg', '5fa9c055-2734-4b08-a049-cda4f460fc05.jpg', 'c115250b-209a-4ad8-b946-30d5dc242cd3.jpg', '9451659d-b7e7-465d-b49a-feffebc54e8b.jpg', 'db6f4bf2-4eda-45b3-930e-a71f83c2f7ef.jpg', '9d00d8a8-bfae-4672-8a51-2f658945d66c.png', '8a83d335-d785-407b-bd8b-396a7b322a12.jpg', 'bb746a50-3587-4ede-8e55-4667225cc9d7.jpg', '15f4f152-fff5-4308-9fc1-02a7bd29f0f9.jpg', '9b30c330-1291-4b72-bc05-eb57f6a3d210.png', 'd447cbd0-d4ec-468a-bd85-660a508308cd.jpg', '2556059e-d7f9-4d7d-8def-892d3563e29b.jpg', 'fa810b19-d525-4b80-aece-223c021c00ea.jpg', '0628debe-4429-4d78-b4ad-30f5e951841c.jpg', 'eaf6e612-8007-412e-aa34-853bf7d99f5e.jpg', 'ae8d10f5-719e-4c9c-9932-73d05d7ccff6.jpg', 'ff99f420-ecd8-417c-b52e-4f9bb3ffb913.jpg', '0b4a4fad-0a27-441d-b312-cefde471a722.jpg', '572fdaf6-b494-474d-8a68-9165e32b499d.jpg', '031e09fe-47cd-4523-b8c9-3591b7bd1f3b.jpg', '6189833f-1224-4a66-92b3-983fae9a94d7.jpg', '475dd064-9e29-4060-8b56-df6b439c2ed9.jpg', '5e027f7b-b61a-4835-9d2a-570e65085098.jpg', 'bac11ccb-dbd1-4556-b659-b699656891d5.jpg', 'e5de8e7a-544e-453a-9d7e-4df0e1278636.jpg', '6fc16857-6073-4396-b1a1-f9e97c576422.jpg', '9900dc17-574f-4d8b-975b-5d464d604042.jpg', '38b0aedc-955e-4aed-904a-e49a83c07440.jpg', 'a4db1eb8-04a6-400b-aad8-77c9acca472f.jpg', '37d5ee53-0275-4675-9c20-908313b13dd9.jpg', 'eea84161-cb31-4f24-8c80-657ab937a40f.jpg', 'd5bb95e2-98de-4d96-822f-d38abe0af068.png', '67c7a9cd-d965-4ea9-b046-c7f8fe2f5255.jpg', '418d1a72-1339-4d28-b6fc-61121e1c7f8f.jpg', '682a164b-80cd-4941-9eb9-186a9c8d0cb7.jpg', 'cc39fee9-4f80-4007-9177-5aa5b8169cab.jpg', 'aa26d426-ac7a-449e-9b83-df4893f16225.jpg', '914c7aa7-f7ec-497a-b733-cab96686381b.jpg', 'dd7fe0e8-c3ae-4d30-8a87-d3775b0f5153.jpg', '1c2a753e-7469-4201-a7d1-5381811db92d.jpg', 'cd208e7c-6fe0-4450-aa29-b8db2b72978d.jpg', '6a7d9ff3-3a3e-4820-a61c-eebeae6c41d8.jpg', '3b9b4879-6524-4a35-ba44-66884e106dfd.jpg', '6b89b896-2b5e-4ed8-81d4-9d712a172a7c.jpg', 'e03fe8de-b302-42a2-b679-eb8f92e7aad3.jpg', 'ef7c837f-aae9-4aa2-8785-49ea8cd66d26.jpg', '0659ed65-704f-450e-84f6-a50354b13243.jpg', '678f531c-eec9-430d-8603-a276ab887f99.jpg', '07da8bc1-df13-4b00-8000-f68825234016.jpeg', '522eb42c-d36b-48ba-9671-6cac60ef1bec.jpeg', 'adeed680-a2ab-47d6-86cc-b74f4cca47fb.jpg', 'f14307cb-0dab-4c9d-b392-d1257274ea3d.jpeg', '1032a248-60af-42f7-85e9-95e934072c41.jpeg', 'bf861388-1ec9-4c5d-acd8-debe6f78b42a.jpg', '2f4a14a2-c3a6-4a6d-98d9-1f72722e7185.jpg', '75e4d126-dd57-4824-be14-0a6729a14a4b.jpg', '862932ed-af73-4151-a4f7-5c014c42d93b.jpg', '7e324286-12e5-41f1-8f77-f71184955dbc.jpg', '9518b84c-ad43-489d-9759-1b11d29915f1.jpg', '7e3595d2-284f-43de-84b5-be34b99d229e.jpg', 'bbb3eea4-f36f-4ed4-ac21-7800c4f93f7a.jpg', 'acf178f2-79a6-4959-a80c-3c71d29eb57d.jpg', 'ebae105f-5001-48d2-88bd-d698b5cb9fd4.jpg', '203a3096-684c-42fb-9162-8c343d749500.png', 'bdc9859d-0b4e-4c16-b78d-53826af57bd8.jpg', 'b92dcbb3-4b89-4a83-a122-2029df4db2a7.jpg', '4a00a4ec-3af4-4fd6-8b31-330e5e9bd964.jpg', '8e593331-ec64-466f-9068-0eb52fefa9f2.jpg', 'e0de2075-311e-4a2b-83dc-99d539e7a8df.jpg', '714db76d-d36d-409a-b807-201c5e39ef88.jpg', 'c80c549e-7e0c-4d1d-8495-cb22f5f78c38.jpg', '235f60db-4df4-4203-b538-3018faf34c4f.jpg', '873d5a5f-b8c4-4ecc-861e-fba15b69103e.jpg', '15af24aa-0ddf-472d-b5bb-e4bc37a6c5b6.jpg', '7f212a5e-aa7e-4671-a0e4-18b2ef58e4ea.jpg', 'e1cea510-eb82-48a8-96e8-9b357835ed89.jpg', '7dce9bef-495f-4f0b-ac13-c6e7a7b11a6f.png', 'dbdece79-81d2-4a87-ab8c-6dd11aa5cc69.jpg', '1b70d921-f780-4502-a9c7-81ded4b13f6a.jpg', 'd6e1d584-8874-4640-97d6-ecda570cd5f5.jpeg', '59b7f8bd-8577-4c30-a592-059720b58424.jpg', '062a9627-2453-443c-99d0-549fe98704b0.jpg', 'cac56650-e931-43ec-83c3-192b46ba61ec.jpg', 'c67031f7-3820-4a11-be15-e6ccaffb451d.jpg', '47f87b57-fab9-4dfe-92b7-a165c3a5236c.jpg', '5d5dc4f0-e9a1-4c95-bcd4-2f93dac74e3c.jpg', '94b06684-5d38-4104-bb2d-b9fd3717be4d.jpg', 'b8d33001-d21f-4ac9-8ed0-9523faf9ca3d.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Drones_And_Birds = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "Drones_And_Birds.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_bdatagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_bdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_bgenerator = train_bdatagen.flow_from_directory(\n",
        "    train_Drones_And_Birds,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_bgenerator = test_bdatagen.flow_from_directory(\n",
        "    test_Drones_And_Birds,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neDZq0dFgr35",
        "outputId": "5999ed99-f27b-413c-84d8-316081881a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "b_frac = Bone.fit(\n",
        "    train_bgenerator,\n",
        "    steps_per_epoch=train_bgenerator.samples // 32,\n",
        "    epochs=5,\n",
        "    validation_data=test_bgenerator,\n",
        "    validation_steps=test_bgenerator.samples // 32,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def classifi_image(i):\n",
        "\n",
        "    i = i.resize((150, 150))\n",
        "    i_arr = image.img_to_array(i)\n",
        "    i_arr = np.expand_dims(i_arr, axis=0)\n",
        "    i_arr = i_arr / 255.0\n",
        "\n",
        "    b_pred = Bone.predict(i_arr)\n",
        "\n",
        "    b_labels = ['fractured', 'not_fractured']\n",
        "    bpred_class = b_labels[np.argmax(b_pred)]\n",
        "\n",
        "    return f\"Predicted Class: {bpred_class}\"\n",
        "\n",
        "\n",
        "boneface = gr.Interface(\n",
        "    fn=classifi_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Bone Fracture Idetifier\",\n",
        "    description=\"Upload an MRI image, and the model will classify it as 'fractured', 'not_fractured'\"\n",
        ")\n",
        "\n",
        "\n",
        "boneface.launch()"
      ],
      "metadata": {
        "id": "-faSiC7Zl9jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "bone_path = '/content/Bone_Fracture_Dataset.zip'\n",
        "\n",
        "bone_folder_path = '/content/bone_fracture_dataset'\n",
        "\n",
        "with zipfile.ZipFile(bone_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(bone_folder_path)\n",
        "\n",
        "bone_files = os.listdir(bone_folder_path)\n",
        "print(\"Extracted files:\", bone_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ldRIrCnh7Fy",
        "outputId": "dfe2703a-a0b2-4543-f82a-4c4fa34b5393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['Bone_Data_Set']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bone_fr_path = os.path.join(bone_folder_path, 'Bone_Data_Set')\n",
        "bone_files = os.listdir(bone_fr_path)\n",
        "\n",
        "print(\"Contents of 'bone_fracture' folder:\", bone_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7R0YQFimR-r",
        "outputId": "0c718e0d-bd81-4758-8d33-cee8aa677a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'bone_fracture' folder: ['train', 'val']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_bone = os.path.join(bone_fr_path, 'train')\n",
        "test_bone = os.path.join(bone_fr_path, 'val')\n",
        "\n",
        "train_bfiles = os.listdir(train_bone)\n",
        "test_bfiles = os.listdir(test_bone)\n",
        "\n",
        "print(\"Training files:\", train_bfiles)\n",
        "print(\"Testing files:\", test_bfiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHKL0_s1mWzY",
        "outputId": "08536147-6011-4ec9-a2cb-5eecd94ce48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['not fractured', 'fractured']\n",
            "Testing files: ['not fractured', 'fractured']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Bone = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "Bone.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_bdatagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_bdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_bgenerator = train_bdatagen.flow_from_directory(\n",
        "    train_bone,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_bgenerator = test_bdatagen.flow_from_directory(\n",
        "    test_bone,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZKmTEsMmcIL",
        "outputId": "be8e7c07-045b-481c-c695-5f89fd126328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8863 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_frac = Bone.fit(\n",
        "    train_bgenerator,\n",
        "    steps_per_epoch=train_bgenerator.samples // 32,\n",
        "    epochs=5,\n",
        "    validation_data=test_bgenerator,\n",
        "    validation_steps=test_bgenerator.samples // 32,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNeutC5TmjRf",
        "outputId": "c4e20ad6-b950-455c-b5ad-e1823a857dd4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276/276 - 289s - 1s/step - accuracy: 0.6239 - loss: 0.6358 - val_accuracy: 0.6597 - val_loss: 0.6216\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276/276 - 5s - 19ms/step - accuracy: 0.6562 - loss: 0.6010 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 3/5\n",
            "276/276 - 293s - 1s/step - accuracy: 0.7794 - loss: 0.4575 - val_accuracy: 0.6597 - val_loss: 0.5742\n",
            "Epoch 4/5\n",
            "276/276 - 1s - 5ms/step - accuracy: 0.7812 - loss: 0.3619 - val_accuracy: 0.7500 - val_loss: 0.4786\n",
            "Epoch 5/5\n",
            "276/276 - 290s - 1s/step - accuracy: 0.8677 - loss: 0.2987 - val_accuracy: 0.6892 - val_loss: 0.6287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classifi_image(i):\n",
        "\n",
        "    i = i.resize((150, 150))\n",
        "    i_arr = image.img_to_array(i)\n",
        "    i_arr = np.expand_dims(i_arr, axis=0)\n",
        "    i_arr = i_arr / 255.0\n",
        "\n",
        "    b_pred = Bone.predict(i_arr)\n",
        "\n",
        "    b_labels = ['fractured', 'not_fractured']\n",
        "    bpred_class = b_labels[np.argmax(b_pred)]\n",
        "\n",
        "    return f\"Predicted Class: {bpred_class}\""
      ],
      "metadata": {
        "id": "rlE23mVtmnqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boneface = gr.Interface(\n",
        "    fn=classifi_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Bone Fracture Idetifier\",\n",
        "    description=\"Upload an MRI image, and the model will classify it as 'fractured', 'not_fractured'\"\n",
        ")\n",
        "\n",
        "\n",
        "boneface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kF9xENS6hl0m",
        "outputId": "c5b273ec-60cb-4be4-cada-5dcad339de83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96ba704c80a3a44c28.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://96ba704c80a3a44c28.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "YuEdtr4-rQ6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a24237e-47a6-46e3-9f41-87ad7ca0ef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omSFrfz3rs-F",
        "outputId": "970fda58-d97d-4028-dca7-8600832329e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import zipfile\n",
        "\n",
        "cataract_path = '/content/Cataract DataSet.zip'\n",
        "\n",
        "cataract_folder_path = '/content/cataract_dataset'\n",
        "\n",
        "with zipfile.ZipFile(cataract_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cataract_folder_path)\n",
        "\n",
        "cataract_files = os.listdir(cataract_folder_path)\n",
        "print(\"Extracted files:\", cataract_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0dKxWT7q1t9",
        "outputId": "03bfbfd2-2b1e-40eb-b8b0-718d7ad4342b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['Cataract DataSet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cataract_data_path = os.path.join(cataract_folder_path, 'Cataract DataSet')\n",
        "cataract_files = os.listdir(cataract_data_path)\n",
        "\n",
        "print(\"Contents of 'cataract' folder:\", cataract_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKKr5jnvuKcd",
        "outputId": "6872afcb-5169-4407-cc55-fee85b3a3c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'cataract' folder: ['Processed Image']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cataract_data_path=os.path.join(cataract_data_path, 'Processed Image')\n",
        "cataract_files = os.listdir(cataract_data_path)\n",
        "\n",
        "print(\"Contents of 'cataract' folder:\", cataract_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF8yIZ52u1gF",
        "outputId": "4b28f8f7-874a-4555-ce68-76e50c2bf615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'cataract' folder: ['Testing', 'Training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_cataract = os.path.join(cataract_data_path, 'Training')\n",
        "test_cataract = os.path.join(cataract_data_path, 'Testing')\n",
        "\n",
        "train_cfiles = os.listdir(train_cataract)\n",
        "test_cfiles = os.listdir(test_cataract)\n",
        "\n",
        "print(\"Training files:\", train_cfiles)\n",
        "print(\"Testing files:\", test_cfiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8hyykLUuQhx",
        "outputId": "cf3d0eb7-c330-4fec-d752-923fce94e2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['Normal', 'Cataract']\n",
            "Testing files: ['Normal', 'Cataract']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cataract = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "Cataract.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "train_cdatagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_cdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_cgenerator = train_cdatagen.flow_from_directory(\n",
        "    train_cataract,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_cgenerator = test_cdatagen.flow_from_directory(\n",
        "    test_cataract,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_yOgDdauWVz",
        "outputId": "c4a9450e-11b8-420a-e3ab-94eafe22034c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 2 classes.\n",
            "Found 30 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_frac = Cataract.fit(\n",
        "    train_cgenerator,\n",
        "    steps_per_epoch=train_cgenerator.samples // 32,\n",
        "    epochs=5,\n",
        "    validation_data=test_cgenerator,\n",
        "    validation_steps=test_cgenerator.samples // 32,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVbiDzO5ueSP",
        "outputId": "500f34c3-9d80-4b11-b9ca-6aa2ddf7bad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 9s - 9s/step - accuracy: 0.5000 - loss: 0.7118 - val_accuracy: 0.5000 - val_loss: 7.5631\n",
            "Epoch 2/5\n",
            "1/1 - 7s - 7s/step - accuracy: 0.5000 - loss: 7.4252 - val_accuracy: 0.5000 - val_loss: 0.9397\n",
            "Epoch 3/5\n",
            "1/1 - 5s - 5s/step - accuracy: 0.5000 - loss: 0.9193 - val_accuracy: 0.5000 - val_loss: 0.6981\n",
            "Epoch 4/5\n",
            "1/1 - 4s - 4s/step - accuracy: 0.5000 - loss: 0.6986 - val_accuracy: 0.5000 - val_loss: 0.6873\n",
            "Epoch 5/5\n",
            "1/1 - 4s - 4s/step - accuracy: 0.5000 - loss: 0.6877 - val_accuracy: 0.7667 - val_loss: 0.6682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_cataract_image(i):\n",
        "\n",
        "    i = i.resize((150, 150))\n",
        "    i_arr = image.img_to_array(i)\n",
        "    i_arr = np.expand_dims(i_arr, axis=0)\n",
        "    i_arr = i_arr / 255.0\n",
        "\n",
        "    c_pred = Cataract.predict(i_arr)\n",
        "\n",
        "    c_labels = ['cataract', 'normal']\n",
        "    cpred_class = c_labels[np.argmax(c_pred)]\n",
        "\n",
        "    return f\"Predicted Class: {cpred_class}\"\n"
      ],
      "metadata": {
        "id": "3Ws0av-ouh4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cataract_interface = gr.Interface(\n",
        "    fn=classify_cataract_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Cataract Detector\",\n",
        "    description=\"Upload an eye image, and the model will classify it as 'cataract' or 'normal'.\"\n",
        ")\n",
        "\n",
        "cataract_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "9JZDrtVZq1R_",
        "outputId": "9fa306de-458b-4546-a3d2-499f0c869efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://60e58938c9a3b874e6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://60e58938c9a3b874e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7r5RZHDQHHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyqzbHbVQI9F",
        "outputId": "f745d651-0a85-474c-97a9-690d62b2539a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.12.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.4 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.5.4)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPZNEGp2QI5e",
        "outputId": "2e537049-1740-43f1-f33b-8c4e01dcb73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import zipfile\n",
        "\n",
        "driver_path = '/content/Driver_Activity.zip'\n",
        "driver_folder_path = '/content/driver_behavior_dataset'\n",
        "\n",
        "with zipfile.ZipFile(driver_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(driver_folder_path)\n",
        "\n",
        "driver_files = os.listdir(driver_folder_path)\n",
        "print(\"Extracted files:\", driver_files)"
      ],
      "metadata": {
        "id": "Dsgal8jVQXpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02dabae-6f33-466f-a0da-4af734d91261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['Driver_Activity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Drivers_Fr_path= os.path.join(driver_folder_path, 'Driver_Activity')\n",
        "Drivers_Fr_files = os.listdir(Drivers_Fr_path)\n",
        "\n",
        "print(\"Contents of 'bone_fracture' folder:\", Drivers_Fr_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACG5qxGN8VJ9",
        "outputId": "8871d217-2648-4311-d8cc-3cc2ffb44d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'bone_fracture' folder: ['Driving Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Drivers_Fr_files_path= os.path.join(Drivers_Fr_path, 'Driving Dataset')\n",
        "Drivers_Fr_files_files = os.listdir(Drivers_Fr_files_path)\n",
        "\n",
        "print(\"Contents of 'bone_fracture' folder:\", Drivers_Fr_files_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJePD8kk8vxO",
        "outputId": "4c566035-8626-4569-d7ff-bddb32c1d70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'bone_fracture' folder: ['Testing', 'Training']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_driver = os.path.join(Drivers_Fr_files_path, 'Training')\n",
        "test_driver = os.path.join(Drivers_Fr_files_path, 'Testing')\n",
        "\n",
        "train_files = os.listdir(train_driver)\n",
        "test_files = os.listdir(test_driver)\n",
        "\n",
        "print(\"Training files:\", train_files)\n",
        "print(\"Testing files:\", test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3qJLXPq5ZLF",
        "outputId": "6237c5d4-d157-48ed-a7fc-3b84c72fa3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['Talking_Phone', 'Safe_Driving']\n",
            "Testing files: ['Talking_Phone', 'Safe_Driving']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DriverBehavior = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "DriverBehavior.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_driver,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_driver,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTM_Zd6k5fHq",
        "outputId": "cd25c383-c6f5-4c76-c314-03db28f19f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 2 classes.\n",
            "Found 30 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver_behavior_model = DriverBehavior.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // 32,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEFhw4BCDFh-",
        "outputId": "786365de-05c1-4696-d50c-891fb99c51bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 4s - 4s/step - accuracy: 0.4667 - loss: 0.6999 - val_accuracy: 0.5000 - val_loss: 4.7633\n",
            "Epoch 2/10\n",
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 4.5613 - val_accuracy: 0.5000 - val_loss: 2.7482\n",
            "Epoch 3/10\n",
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 2.5287 - val_accuracy: 0.5000 - val_loss: 0.7176\n",
            "Epoch 4/10\n",
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.7120 - val_accuracy: 0.5000 - val_loss: 0.7128\n",
            "Epoch 5/10\n",
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.7031 - val_accuracy: 0.5000 - val_loss: 0.6905\n",
            "Epoch 6/10\n",
            "1/1 - 3s - 3s/step - accuracy: 0.6000 - loss: 0.6811 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 7/10\n",
            "1/1 - 2s - 2s/step - accuracy: 0.6333 - loss: 0.6706 - val_accuracy: 0.5000 - val_loss: 0.6900\n",
            "Epoch 8/10\n",
            "1/1 - 3s - 3s/step - accuracy: 0.4333 - loss: 0.6964 - val_accuracy: 0.8667 - val_loss: 0.6787\n",
            "Epoch 9/10\n",
            "1/1 - 4s - 4s/step - accuracy: 0.5000 - loss: 0.6881 - val_accuracy: 0.5000 - val_loss: 0.6745\n",
            "Epoch 10/10\n",
            "1/1 - 3s - 3s/step - accuracy: 0.6667 - loss: 0.6734 - val_accuracy: 0.9000 - val_loss: 0.6681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_driver_behavior(img):\n",
        "    img = img.resize((150, 150))\n",
        "    img_arr = image.img_to_array(img)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = img_arr / 255.0  # Normalize\n",
        "\n",
        "    prediction = DriverBehavior.predict(img_arr)\n",
        "    behavior_labels = ['Safe Driving', 'talking_phone']\n",
        "    predicted_behavior = behavior_labels[np.argmax(prediction)]\n",
        "\n",
        "    return f\"Predicted Behavior: {predicted_behavior}\"\n"
      ],
      "metadata": {
        "id": "HfMRE3OxDLwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_interface = gr.Interface(\n",
        "    fn=classify_driver_behavior,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Driver Behavior Identifier\",\n",
        "    description=\"Upload a driver image, and the model will classify it into behaviors like 'Safe Driving', 'talking_phone'\"\n",
        ")\n",
        "\n",
        "driver_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Pfpfi_DICAHm",
        "outputId": "f78c9b7e-2588-4ff6-b1a7-522b1f647914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://75b2782c9a73362b8e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://75b2782c9a73362b8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Unzipping the dataset\n",
        "dataset_path = '/content/Pediatric Chest X-ray Pneumonia.zip'\n",
        "dataset_folder_path = '/content/chest_xray'\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_folder_path)\n",
        "\n",
        "dataset_files = os.listdir(dataset_folder_path)\n",
        "print(\"Extracted files:\", dataset_files)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB84rPH9PLuU",
        "outputId": "c9c17e41-dc06-4b67-d399-49505bc7036e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['train', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(dataset_folder_path, 'train')\n",
        "test_path = os.path.join(dataset_folder_path, 'test')\n",
        "\n",
        "train_files = os.listdir(train_path)\n",
        "test_files = os.listdir(test_path)\n",
        "\n",
        "print(\"Training files:\", train_files)\n",
        "print(\"Testing files:\", test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChBvNd9JPpar",
        "outputId": "5e8706b4-8352-4bed-a9e5-fe769823898b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['NORMAL', 'PNEUMONIA']\n",
            "Testing files: ['NORMAL', 'PNEUMONIA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Chest_XRay = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "Chest_XRay.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02WPC8s6P947",
        "outputId": "aa5e1f00-7a95-42df-948e-56460ded7715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5232 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = Chest_XRay.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    epochs=5,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // 32,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "ujGbfM5EQFjW",
        "outputId": "7c09efc8-56e7-4bfb-fbe1-07c4cf1a50b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 - 228s - 1s/step - accuracy: 0.8554 - loss: 0.3424 - val_accuracy: 0.8783 - val_loss: 0.3052\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 - 2s - 10ms/step - accuracy: 0.9062 - loss: 0.1488 - val_accuracy: 0.8750 - val_loss: 0.2713\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-2366310a980f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = Chest_XRay.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_chest_xray(image_input):\n",
        "    image_input = image_input.resize((150, 150))\n",
        "    img_array = image.img_to_array(image_input)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    predictions = Chest_XRay.predict(img_array)\n",
        "    labels = ['pneumonia', 'Normal']\n",
        "    predicted_class = labels[np.argmax(predictions)]\n",
        "\n",
        "    return f\"Predicted Class: {predicted_class}\""
      ],
      "metadata": {
        "id": "7m4yEK-6TRYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chest_xray_interface = gr.Interface(\n",
        "    fn=classify_chest_xray,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Chest X-Ray Identifier\",\n",
        "    description=\"Upload a chest X-ray image, and the model will classify it as 'pneumonia', or 'healthy'.\"\n",
        ")\n",
        "\n",
        "chest_xray_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "ZxyFdUilPLq8",
        "outputId": "450a44ac-aa30-4058-f1ea-d0f1f4b81f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a6a5c3dcb8fd83bb5c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a6a5c3dcb8fd83bb5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9S5Be-JW03b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import zipfile\n",
        "\n",
        "dataset_path = '/content/Drone_And_Birds 00.zip'\n",
        "extracted_folder_path = '/content/Drone_Birds_dataset'\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "dataset_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", dataset_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B72Rai5ZW2rv",
        "outputId": "1cf25a32-49f7-4fcb-e416-0b773db345a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['drone_or_bird', 'Drone_And_Birds']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = os.path.join(extracted_folder_path, 'drone_or_bird')\n",
        "data_files = os.listdir(data_folder_path)\n",
        "\n",
        "print(\"Contents of the dataset folder:\", data_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTumPGC5XMb1",
        "outputId": "c506cc2d-5bf0-4153-8bbc-8243e3f74635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of the dataset folder: ['drones', 'birds']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(data_folder_path, 'drones')\n",
        "test_path = os.path.join(data_folder_path, 'birds')\n",
        "\n",
        "train_files = os.listdir(train_path)\n",
        "test_files = os.listdir(test_path)\n",
        "\n",
        "print(\"Training files:\", train_files)\n",
        "print(\"Testing files:\", test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38SkKTo5Xu4c",
        "outputId": "03601596-cdb2-4a17-edf5-8d071036f0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: ['aef5a535-4170-4752-bdfa-07da5f32430f.jpg', 'fc81b00c-048f-432e-9251-517586852c3e.jpg', '1efe6d9f-dd1c-4429-be1d-9260769e1f3b.jpeg', 'df31167f-263e-4113-a365-2883c34c039c.jpg', '02f16ac8-d7fe-4cf0-96db-5cb940bbe887.jpg', 'a0e17740-a126-44f2-adfd-4876974d1934.jpg', 'e17c99fc-70fb-428a-a95c-a6887eb52ea9.jpg', 'db81ca1c-d9b2-43e2-9b17-42b9ebbc2795.jpg', 'bd658de4-599d-4d59-be88-59af608f83c0.jpg', '329ffc5b-04ea-4418-aba4-afd55e435b0d.jpg', 'b6a01ab8-5e12-4397-8965-cd50ec937650.jpg', 'db950a8d-dfcf-49ba-978a-67035b8b842b.jpg', 'eb6f76d0-b5eb-4f73-a6d2-9e668d392faf.jpg', '07aadf09-547b-47c6-bc9b-46189ac4bd4c.jpg', '1d843c8d-5c7d-469b-a0e1-b31802a34eba.jpg', '993681c8-b017-4d11-9dca-aaba97e19955.jpg', 'd40c2067-03e5-4116-a252-dcc2623c606f.jpg', 'a2e1205e-5ed5-46f1-8ffb-63f1969e98c1.jpg', '1e9f33d0-7300-42bc-9bd6-326e9f07e59f.jpg', '2fe4681a-a92d-4a5a-8d45-9f79cae9861e.jpg', 'ec1f1f15-96be-466a-8004-31ada86da743.jpg', 'da0864d8-3ea1-4494-a76e-8db4ec2af71a.jpeg', 'c978c190-463b-49af-bd61-c63c5ad19c14.jpg', 'a8e83d7a-6071-479c-bc25-9320f6ad1316.png', '1f25afbe-58a5-4627-919b-fc171b920e24.jpg', 'f3617a75-d433-4cb4-b8b5-31150411cfa7.jpg', '600eb4ea-740f-4d5e-9de9-a2f6a5f5a6c9.jpg', '1b462dac-09b5-4ccf-a001-a935c23d06cb.jpg', '0375f047-313c-440b-a6c2-9b82a209547d.jpg', '329b8da7-6e60-441d-81fc-eac9118cd239.gif', 'b82a62a0-e00e-4060-ad53-4cdfe13b0eee.bmp', 'f9914802-1499-4fd0-a43c-7eb94b158836.jpg', 'a75af03e-a1f4-484f-a44c-ddea9e5186c4.jpg', '0e3dcfd8-9162-43e3-aeeb-ef7b03ddf304.jpg', 'c7a75f37-3cf3-4526-a8af-6961b7f3f0fd.jpg', 'e7528219-42bf-498b-a277-3d38b58e58e3.jpg', 'c0482e08-798c-493c-a23e-c1e792bb4a48.jpg', 'f64005c8-4e8a-444d-9318-73acfbe2fa0f.jpg', '3475059c-99dd-4692-9816-6cbfba9c1f17.jpg', 'df543bdd-b483-4ee4-a0f0-aed44d31fafd.jpg', 'd6c39ef3-7d18-4744-8146-71a2865b0c36.jpg', 'f072177b-e55f-4d0d-b6d5-9489feb52d4a.jpg', '22923177-9130-4e69-942a-59f0a649adcc.jpg', '92305393-af49-491e-9b48-7b038340a4b7.jpg', '253696fc-94ab-40a8-b77d-9549ff839216.jpg', 'bd7cd86b-b681-4c16-b116-47c08b9274dd.jpg', '2b977f7b-e79b-4ffb-97ff-1c6bd35adf00.jpg', 'cd4f1973-2616-403b-b61d-93f7423ce8e8.jpg', 'd1a78686-213d-4435-817e-6fa65b851981.png', '0eeb3e6b-9818-49ff-b76f-acbd2d443fa6.jpg', 'dd0b0b16-ef21-4c11-b2d2-986f4ef1a622.jpg', 'c0eacb5e-7e9a-48de-ab4e-af7d7f916a61.jpg', '692a442c-4394-44be-8302-5bed57ad457f.jpg', 'ce051209-66b2-473d-8347-222a1dc16c76.jpg', '0dd388ec-0aea-420f-a2e8-b88752991475.jpg', 'd112bc6f-6c66-4d57-9dbb-667213976256.jpg', 'ebf611ea-45db-4778-b031-0c4a312105c3.jpg', 'cdfb0e09-62d3-4da8-90cd-2129b3a11d37.JPG', 'a45d86cb-c478-4dec-984d-061adfccde4c.jpg', 'a3240e0a-4132-46a8-9e34-3dd722229703.jpg', '565e4ba0-3f52-4490-b937-f4f3789512f9.jpgupdated201605201717imageversionFacebookexactH630exactW1200exactfitcropnoborder', '27988a77-56a0-4cce-9af8-dde7c5772fc7.jpg', 'd1a025f7-2afb-4f6a-a501-0df63e524d10.jpg', '42425985-c7a9-436c-9f80-760dc9dbfe18.jpeg', 'a25c1458-2bb6-4444-9fef-0da55f1f6e7f.jpg', 'a16892c3-c237-4acf-ad9d-3d7c8a94a49e.jpg', 'df1df129-e166-405f-9bf8-247257391a16.jpeg', '62866ecc-1ea3-4f20-bbb5-4cd6837001f8.jpg', '27679331-6a42-484f-869f-e5e9965f9d0b.jpg', 'd7330acc-5832-4b8d-9c8f-0030896036c2.jpg', '108759dc-ad0c-4df0-95cf-818b30c30970.jpg', 'd228e6ea-fffb-480d-bb04-1d29961c9648.jpg', 'c6f4657d-a767-4168-84fa-4e2960f15bfc.jpg', 'fb534322-57e9-4f9c-8b17-4def9622e05f.jpg', 'd7fb940c-e421-4a1f-97b0-faf324331cb7.jpg', '6dd7c5c0-8982-41cd-8205-522b53910a5e.gif', '5660208d-3728-4cc1-b8c2-fa571d822126.jpg', '099703dd-0294-471f-96de-ebf871937906.jpg', 'f0939d8f-b1e5-4448-9fa7-4efcc2a8981b.jpg', '34019870-235f-446d-a10c-11e00be504b1.jpg', '2ddf8e9a-5c04-4a66-98eb-9fb73d4b130f.jpg', '0e1676df-c3e9-44de-aa4a-1e28d23bde13.jpg', 'ffc25b22-1c0f-4952-9e12-ee117cb3d09d.jpg', '703decd0-9cdb-4187-84d9-aa24702486a9.jpg', 'e14ba81b-a9ac-4c69-8c7b-8661ec02f873.jpg', '991407df-d9c4-4891-867f-04a41a47c848.jpg', 'fae177b1-b184-445d-b965-23e607399fae.png', '80114510-c1f8-47ac-b568-d0aaf0908a94.JPG', '2e5c027a-68b0-452a-9e42-56e3bcfa1259.jpg', '410067dd-25a1-451e-aa01-dad93daf0a17.jpg', '82050651-91da-4f2d-992d-ac68e6078731.jpg', '455739cf-4357-4098-9783-652871f88b37.jpg', 'b90466aa-5560-41ef-b345-00fad35af751.jpeg', 'f6bb3595-ce46-4c88-997b-c0f7f1797b84.jpg', 'c89b265e-8bf8-44a2-9df8-56069716d76f.jpg', 'b36f2943-7ead-4472-942f-0436529fc4c4.jpeg', '9680900c-de20-4dcb-b761-3fc45172b10e.jpg', 'caefaea3-aaab-438b-89e5-bf4accde0ac9.jpg', 'e49598c5-faf9-480c-8be5-eae268674c33.jpeg', 'bc3e592d-5fcd-4e0b-9f0b-ed13018e2a8d.jpg', '0691d67b-0e62-4e74-a7c7-bef9924d083a.jpg', 'eedfa861-d7f3-44d0-8117-9a6037c0000c.jpg', 'fd660a1b-5362-4e57-b281-f78771cc5c63.jpg', 'c917ba9f-496f-449c-a2e3-0781cbfd8f0b.jpg', 'c575f265-cec4-4e5e-8eba-5614fc749ed1.jpg', 'cf43c64a-503d-4005-aa31-48c6fa423f2c.jpg', 'a565ba39-a3a6-44fb-b055-9ec37d2b1bb1.jpg', 'edb7ed01-e88f-44c8-9655-a6ece0424ab8.png', 'cf5de35a-9d2f-45bf-8935-e03bb18d741f.jpg', 'bc7ada80-4161-4395-a107-78bd376282c1.jpg', 'ae4c12a4-2b60-404e-8822-a9dad0fc1dfb.jpg', '2ff83b8e-0c85-4519-9b8a-e2ce33d8abec.jpg', '0ff3da67-09bd-41e0-87d1-2d665ea00208.png', 'bef22d2c-2d17-4e0f-8a07-bf451426bff2.jpg', 'c5bca0d7-94b3-42f9-80e7-69822bff2c98.jpg', '1c5bb3a9-21d1-4234-abb1-e284f070d67e.png', '50652a6e-f308-492b-b3e3-d55f1e57637b.jpg', 'bf4c5f97-d3bc-4290-adec-e55b4ef0e298.jpg', 'd4a7a433-f25c-4637-9c9b-f75c63fd6f11.jpg', 'af315f2a-7284-4afb-babd-a81cea0e8d11.jpg', 'a553bd72-5e9f-4232-8ef5-59a95f225359.jpg', 'e5ed9253-3142-4bc7-8ee3-5e6c8b0e8e45.png', '7713239a-50f6-4e4c-9cdb-2144a067d4b4.jpg', 'd72a6b08-bdb3-417b-a524-5842178877b5.jpg', 'a5ef3933-0dcd-4edb-8061-3aa10264237b.jpg', 'e4a0ed61-ee8b-4020-8038-410b9e88722f.jpg', '37452103-9786-4f63-a6ac-64bd46044d7c.jpg', 'cd0aa537-b032-46d2-a110-6c1548bff5a4.jpg', '665c1c53-1328-43cc-97f3-a4f0e81a4ec5.jpg', 'd27da3b6-269c-4dad-bd2d-13e267e897cf.jpg', 'f60353e3-6cce-4ffa-8c59-b8ccc4886130.jpg', 'dd02d817-6040-4668-89dd-f9a2a307216d.jpg', '65996eab-2a44-4760-b7db-50398ea9791d.jpg', 'a1294f17-94dd-4c78-a7f9-cd8086227c73.jpg', 'ef80a820-7e99-4efa-8d1e-4d61da59ec0e.jpeg', 'f6c3f42c-5095-4cc9-8128-5d2cdeb5e870.jpg', '1e3fa0c9-8eda-474e-95b2-e70558f74d4e.jpg', '539dbba3-2281-4383-804e-8caff40e13b6.jpg', '0dbf5fed-e6cd-4e0e-919c-72abeb6ff2e1.jpg', '470ec2a1-0179-40de-8574-d09734df989f.jpg', '0f9b27ce-40f7-4a38-b329-86e0f62a8a95.jpg', 'a3b8d577-b6ef-400f-a3ba-057549da528a.jpg', 'bb36682f-4bc1-4dcf-813e-f1ee14b1cf7f.jpg', 'a461bb93-1577-4663-a5c4-5652b91b14ac.jpg', '9458480e-48e7-4d25-a53c-c1638acf4c3f.jpg', 'ee3ac2eb-8f97-4264-b869-2142ada758e4.jpg', 'd77e3361-9363-421b-8bd9-77806d8f5f06.jpg', '0f54face-8758-4f3b-8231-443bf085a94c.jpg', '1bfe7020-7aed-4e34-a2b3-72bc185e843b.jpg', 'cd4e5ef2-c64a-462a-a0ee-c6c0a6d42bd5.bmp', 'e4bb86e0-7db0-443c-b5bd-2fb711d6a396.jpg', 'fccd1ca4-a63c-469e-813d-85a912f516ef.png', '3a96ece1-537c-4890-b98b-a884d0b096b0.jpg', 'f4ffc10f-426e-443a-95db-7d4280035efe.jpg', '1bddb405-632c-4881-a80d-5fe78f476737.jpg', '06d6c3f4-f655-4d0f-b18a-a4ae78f5983f.jpg', 'c617f8ac-74db-41a4-8bc1-aace9601f01f.jpg', 'ddfa8041-c562-41b8-8700-cdc11f0cb4c3.jpg', 'e58b3de3-c147-4b73-833a-3a8f99e8d82b.jpg', '71826869-8385-45f9-8b42-4a54c614c3b5.jpg', '0ce60dde-ed13-4fd3-85b9-0a824e51676c.jpg', 'cfb6d952-8d6a-41c8-9b32-412b5f914018.jpg', '531e9b13-4528-4cc3-a7d9-ff2c89075b53.jpg', '540bad82-4b8a-46a7-8ce6-681d4fd38399.jpg', '202036d2-af55-4a10-844d-89fc7a575730.jpg']\n",
            "Testing files: ['a336c0fd-6bcc-44e3-affa-418edbddc287.jpg', 'c2f47e10-f4b7-40ff-b81a-580470f89378.jpg', 'b4f75094-47d7-41e5-8df2-81be896a82bd.jpg', '572fdaf6-b494-474d-8a68-9165e32b499d.jpg', '0adf7f21-6068-47f0-84f0-c464f855a85d.jpg', 'ca5657fc-f615-4153-bc6a-771b0f3344ed.jpg', '07da8bc1-df13-4b00-8000-f68825234016.jpeg', '1c2a753e-7469-4201-a7d1-5381811db92d.jpg', '7e324286-12e5-41f1-8f77-f71184955dbc.jpg', 'c115250b-209a-4ad8-b946-30d5dc242cd3.jpg', 'bf861388-1ec9-4c5d-acd8-debe6f78b42a.jpg', '2f4a14a2-c3a6-4a6d-98d9-1f72722e7185.jpg', '0b4a4fad-0a27-441d-b312-cefde471a722.jpg', '9329b9d4-e34e-40cf-a4d7-f7880c0ffc38.jpg', '5fa9c055-2734-4b08-a049-cda4f460fc05.jpg', 'bac11ccb-dbd1-4556-b659-b699656891d5.jpg', 'c6851fde-6268-477b-ad27-96ab44ef917a.jpg', 'db6f4bf2-4eda-45b3-930e-a71f83c2f7ef.jpg', 'c80c549e-7e0c-4d1d-8495-cb22f5f78c38.jpg', '59b7f8bd-8577-4c30-a592-059720b58424.jpg', '475dd064-9e29-4060-8b56-df6b439c2ed9.jpg', '6a7d9ff3-3a3e-4820-a61c-eebeae6c41d8.jpg', 'd5bb95e2-98de-4d96-822f-d38abe0af068.png', '2b6f9be8-c93c-4260-9e2c-9fb2036c6493.jpg', '15f4f152-fff5-4308-9fc1-02a7bd29f0f9.jpg', 'ae8d10f5-719e-4c9c-9932-73d05d7ccff6.jpg', 'e9188796-d823-47c1-8007-75946116ea1e.jpg', 'f14307cb-0dab-4c9d-b392-d1257274ea3d.jpeg', 'bb746a50-3587-4ede-8e55-4667225cc9d7.jpg', 'd447cbd0-d4ec-468a-bd85-660a508308cd.jpg', '678f531c-eec9-430d-8603-a276ab887f99.jpg', '15b61826-3ea0-407d-8be8-7e97fbf260a2.jpeg', 'a9ea09f3-5c1a-4497-a68f-437af324c5d0.png', 'cc39fee9-4f80-4007-9177-5aa5b8169cab.jpg', 'e5de8e7a-544e-453a-9d7e-4df0e1278636.jpg', '4540c21a-c93c-4ed3-bf7a-2ba51fb0a756.jpg', 'eea84161-cb31-4f24-8c80-657ab937a40f.jpg', '8db30af7-ca36-4a6e-b7ae-b23c335e4df2.jpeg', 'd3089f83-ab93-4092-ba55-2a29ec4bff53.JPG', 'fa810b19-d525-4b80-aece-223c021c00ea.jpg', '37d5ee53-0275-4675-9c20-908313b13dd9.jpg', '1e68db20-be3f-49b3-862f-6b91730c1a5b.jpg', 'c4c7281f-02f6-476e-afa7-b3baddde3389.jpg', '47f87b57-fab9-4dfe-92b7-a165c3a5236c.jpg', 'a4db1eb8-04a6-400b-aad8-77c9acca472f.jpg', 'bdc9859d-0b4e-4c16-b78d-53826af57bd8.jpg', '062a9627-2453-443c-99d0-549fe98704b0.jpg', '418d1a72-1339-4d28-b6fc-61121e1c7f8f.jpg', '522eb42c-d36b-48ba-9671-6cac60ef1bec.jpeg', '031e09fe-47cd-4523-b8c9-3591b7bd1f3b.jpg', '9d00d8a8-bfae-4672-8a51-2f658945d66c.png', '203a3096-684c-42fb-9162-8c343d749500.png', 'f3e96d48-5ab7-4d6d-a230-dadee102919c.jpg', '682a164b-80cd-4941-9eb9-186a9c8d0cb7.jpg', '6461fdf2-03fb-4a94-9059-0bae4a4f23a0.jpg', '3b9b4879-6524-4a35-ba44-66884e106dfd.jpg', 'acf178f2-79a6-4959-a80c-3c71d29eb57d.jpg', '7f212a5e-aa7e-4671-a0e4-18b2ef58e4ea.jpg', 'b8d33001-d21f-4ac9-8ed0-9523faf9ca3d.jpg', 'dbdece79-81d2-4a87-ab8c-6dd11aa5cc69.jpg', '9971e9a9-8f9b-4195-821a-0864d9ff008c.jpg', '134c2745-d42c-4e24-bb4f-3738f79de8ae.jpg', '5e027f7b-b61a-4835-9d2a-570e65085098.jpg', '1032a248-60af-42f7-85e9-95e934072c41.jpeg', 'aa0a9a48-1a55-4cc3-a3f9-82e72602efef.jpg', 'c9d28535-682f-4caa-8d13-4fff1fdc1208.jpg', 'f37fdf21-2fc7-479f-b2cf-ce1a0e95a222.jpg', 'e498c87f-666e-483a-8d16-ebdbde850e7e.jpg', '9c239e8a-aad7-42c4-bbc8-ef06e4e660a6.jpeg', '75e4d126-dd57-4824-be14-0a6729a14a4b.jpg', 'ff99f420-ecd8-417c-b52e-4f9bb3ffb913.jpg', '808b86b2-1b47-4493-9ab8-166d86109ac7.jpg', '8f173a2b-5bd4-4f7c-8d48-38008fda125c.jpg', 'e458c1b2-4c80-4a42-b28f-5927bffa507f.png', '914c7aa7-f7ec-497a-b733-cab96686381b.jpg', 'b94c7360-bded-4775-8047-5f1daa569c9d.jpg', '74e686a9-a92c-4ff2-a0bb-9573916f267a.jpg', '5d5dc4f0-e9a1-4c95-bcd4-2f93dac74e3c.jpg', 'a685ee3f-252d-4309-ade3-68a10c35b656.jpg', '6915aff8-ce5c-4e38-b401-237cefaa6ce7.png', '714db76d-d36d-409a-b807-201c5e39ef88.jpg', '7dce9bef-495f-4f0b-ac13-c6e7a7b11a6f.png', 'aa26d426-ac7a-449e-9b83-df4893f16225.jpg', 'cda3bbe2-83f0-4884-b155-848b89d6349a.jpg', '4a00a4ec-3af4-4fd6-8b31-330e5e9bd964.jpg', '873d5a5f-b8c4-4ecc-861e-fba15b69103e.jpg', '9900dc17-574f-4d8b-975b-5d464d604042.jpg', 'c90c58c2-cdcb-4656-8a44-2f27a46d7e21.jpg', '5083960f-20da-434e-a3e8-9858a2e0d2e6.jpg', 'bbea4dd5-01a2-435c-8e7a-523e8109f392.jpg', '6b89b896-2b5e-4ed8-81d4-9d712a172a7c.jpg', 'b2f06b58-6884-4b69-9d58-74c3df7fdd21.jpg', '5460e6f1-c2c2-4b1d-bf25-18666f486d00.jpg', '9518b84c-ad43-489d-9759-1b11d29915f1.jpg', 'fe3580e9-91bb-406f-ad72-a689c6d31e0c.png', '9b30c330-1291-4b72-bc05-eb57f6a3d210.png', '5532e833-e127-4e48-96db-9fa315d15c64.jpg', 'bbb3eea4-f36f-4ed4-ac21-7800c4f93f7a.jpg', '10c0c502-724e-41d6-95e6-fc80ae3b37c6.jpg', 'e1cea510-eb82-48a8-96e8-9b357835ed89.jpg', '30dd033c-90a3-4083-a969-3d6e077e47c8.jpg', '91a3f3e7-7625-44bb-a969-9a79bc30a159.jpg', 'ef7c837f-aae9-4aa2-8785-49ea8cd66d26.jpg', '15af24aa-0ddf-472d-b5bb-e4bc37a6c5b6.jpg', 'e03fe8de-b302-42a2-b679-eb8f92e7aad3.jpg', 'f0cb4e67-c10a-4c36-9b14-73aae7c54d4a.jpg', 'd6e1d584-8874-4640-97d6-ecda570cd5f5.jpeg', 'e44b5602-9218-4789-8bfc-3907bf507bbb.jpg', 'a9c44bf8-c15e-4f3e-9371-7f5ba79551e9.jpg', 'fee75851-cbc5-4063-952f-e341e55dc98a.jpeg', '4a9112e6-ca59-437b-bc43-6d18ad571a7f.jpg', '050a45d2-e917-442f-9979-53f9017a8538.jpg', 'ff605692-ab22-4223-a6ab-a047c9f7976a.jpg', 'b92dcbb3-4b89-4a83-a122-2029df4db2a7.jpg', '0659ed65-704f-450e-84f6-a50354b13243.jpg', '2eab572e-665a-42a9-9a63-f819b834a755.jpg', 'e0de2075-311e-4a2b-83dc-99d539e7a8df.jpg', '2829a581-b5de-4161-bf1b-b6d9b78b6a94.jpg', '38b0aedc-955e-4aed-904a-e49a83c07440.jpg', '56ce4aab-3d02-4749-b872-1d31bfd8b476.jpg', '6189833f-1224-4a66-92b3-983fae9a94d7.jpg', 'c67031f7-3820-4a11-be15-e6ccaffb451d.jpg', '0a5b4074-52c7-42d5-8b5e-54b4f93fc129.jpg', 'cb5aa262-b03a-4e07-82a7-ea7bfcdb84f5.jpg', '145c9486-5884-41b2-a391-ed692360a50b.jpg', '67c7a9cd-d965-4ea9-b046-c7f8fe2f5255.jpg', '44bbf407-7e00-4403-be0a-c3f1270fe98f.jpg', '94b06684-5d38-4104-bb2d-b9fd3717be4d.jpg', '08863cbd-4a84-46ae-a5f5-920579de1b6f.png', '8a83d335-d785-407b-bd8b-396a7b322a12.jpg', '7e1d9204-9294-459a-b688-34ab894819ac.jpg', 'a89264b9-02b4-41cf-8d7f-6f7ddef77cde.jpeg', 'cac56650-e931-43ec-83c3-192b46ba61ec.jpg', 'eaf6e612-8007-412e-aa34-853bf7d99f5e.jpg', 'cd208e7c-6fe0-4450-aa29-b8db2b72978d.jpg', 'fdc4966a-559b-4e93-9c56-98b86dacdc0d.jpg', 'fe2f4c22-dc13-43b7-af9a-ed2c901f32b6.jpg', 'ebae105f-5001-48d2-88bd-d698b5cb9fd4.jpg', 'aebd7ed5-b62b-469a-a754-76dd24d1e6a6.jpg', '1b70d921-f780-4502-a9c7-81ded4b13f6a.jpg', '5566456b-9dbe-47fe-b41d-6ed59f33f988.jpg', '0628debe-4429-4d78-b4ad-30f5e951841c.jpg', '3e3069cf-4dcd-4c15-beb6-a63e2264e2d8.jpg', '34d13c1f-e29e-497e-84bd-ac1c897bfa7d.jpg', '4689c884-ed90-43ea-84de-254f8d633f16.jpg', '6fc16857-6073-4396-b1a1-f9e97c576422.jpg', '8e593331-ec64-466f-9068-0eb52fefa9f2.jpg', '9451659d-b7e7-465d-b49a-feffebc54e8b.jpg', '862932ed-af73-4151-a4f7-5c014c42d93b.jpg', '5120b845-b69a-4c1a-9094-5b27144507dc.gif', '0bf9f08a-2693-42e6-ab35-9f08f97e4603.jpg', '84ac73c2-727c-400e-a3c3-1243669e66fa.jpg', '235f60db-4df4-4203-b538-3018faf34c4f.jpg', 'c0ebd711-4bd5-4605-be9e-8f6c8802a5d1.jpg', '0e4aaa7a-92ab-4d96-9a4f-b73f89a44af5.jpg', '775c6102-8c42-407c-9e5a-95a4a496e9f1.jpg', '2556059e-d7f9-4d7d-8def-892d3563e29b.jpg', 'adeed680-a2ab-47d6-86cc-b74f4cca47fb.jpg', 'b70bd575-c88e-4623-87b1-50ef8e065de8.jpg', 'dd7fe0e8-c3ae-4d30-8a87-d3775b0f5153.jpg', 'd6096bea-4369-4b1f-84fd-d09ab245f694.jpg', '7e3595d2-284f-43de-84b5-be34b99d229e.jpg', '0c251caa-9ed5-4f35-bdaa-a632584c8be7.jpg', 'a67634ef-da17-459d-942f-ac6e8f3badbb.jpg', '79d12826-52ff-4528-906d-b8b5c5447ffa.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "Model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j5y79dWX4o_",
        "outputId": "0700c6b3-c267-469c-b5e2-2c3779580ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = Model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    epochs=5,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // 32,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Prediction function\n",
        "def classify_image(img):\n",
        "    img = img.resize((150, 150))\n",
        "    img_arr = image.img_to_array(img)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = img_arr / 255.0\n",
        "\n",
        "    pred = Model.predict(img_arr)\n",
        "\n",
        "    labels = ['Airplane', 'Bird']\n",
        "    pred_class = labels[np.argmax(pred)]\n",
        "\n",
        "    return f\"Predicted Class: {pred_class}\"\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Airplane vs Bird Classifier\",\n",
        "    description=\"Upload an image, and the model will classify it as 'Airplane' or 'Bird'.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "rABLnMAXW01B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iB1sCaU5S5cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAlwyio9T0qH",
        "outputId": "6bdd9102-bdfc-44a3-e9f6-e103cec9cba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hydhaJXGT0ml",
        "outputId": "e1848a66-882c-498d-d21d-6d5aa80161cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import zipfile\n",
        "\n",
        "# Unzipping the dataset\n",
        "driver_behavior_path = '/content/Driver_Activity.zip'\n",
        "driver_behavior_folder = '/content/driver_behavior_dataset'\n",
        "\n",
        "with zipfile.ZipFile(driver_behavior_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(driver_behavior_folder)\n",
        "\n",
        "driver_behavior_files = os.listdir(driver_behavior_folder)\n",
        "print(\"Extracted files:\", driver_behavior_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpE0gd2nYTO1",
        "outputId": "cee40431-4b36-4b3f-de02-486fe6f7a6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['Driver_Activity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver_behavior_files_path = os.path.join(driver_behavior_folder, 'Driver_Activity')\n",
        "driver_behavior_files_files = os.listdir(driver_behavior_files_path)\n",
        "\n",
        "print(\"Contents of 'bone_fracture' folder:\", driver_behavior_files_files)"
      ],
      "metadata": {
        "id": "mhFO-e2aZEOw",
        "outputId": "ccfde318-8fa1-4073-fd35-5bc6ef22cdb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'bone_fracture' folder: ['Driving Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYfz7_e-ZJeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path setup\n",
        "train_path = os.path.join(driver_behavior_folder, 'training')\n",
        "test_path = os.path.join(driver_behavior_folder, 'testing')\n",
        "\n",
        "# Checking dataset structure\n",
        "print(\"Training folder contents:\", os.listdir(train_path))\n",
        "print(\"Testing folder contents:\", os.listdir(test_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_f5CCOUcYpFj",
        "outputId": "aea3f8b7-cb52-4e05-d3cc-c256b92288c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/driver_behavior_dataset/training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-12625d1a4fb0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Checking dataset structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training folder contents:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing folder contents:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/driver_behavior_dataset/training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "DriverBehavior = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')  # Assuming 5 classes for driver behavior\n",
        "])\n",
        "\n",
        "DriverBehavior.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150)\n",
        ")\n",
        "\n",
        "# Model Training\n",
        "driver_behavior_history = DriverBehavior.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // 32,\n",
        "    verbose=2\n",
        ")\n",
        "def classify_image(img):\n",
        "    img = img.resize((150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    predictions = DriverBehavior.predict(img_array)\n",
        "    labels = ['safe_driving', 'texting', 'eating', 'distracted', 'other']  # Update with actual class names\n",
        "    predicted_class = labels[np.argmax(predictions)]\n",
        "\n",
        "    return f\"Predicted Behavior: {predicted_class}\"\n",
        "\n",
        "driver_behavior_interface = gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(),\n",
        "    live=True,\n",
        "    title=\"Driver Behavior Classifier\",\n",
        "    description=\"Upload an image of a driver, and the model will classify the behavior (e.g., 'safe_driving', 'texting').\"\n",
        ")\n",
        "driver_behavior_interface.launch()"
      ],
      "metadata": {
        "id": "o2d9qz1JYOgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WES6sIQZmHiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3UsDuzcx4VB0",
        "outputId": "5d955509-77a0-4c56-8410-dd42b9f44dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2024.12.14)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install speech_to_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J0wJssav4cec",
        "outputId": "4c07bb99-5191-4b22-93ef-a4d3139fd8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speech_to_text\n",
            "  Using cached speech_to_text-0.1.0-py2.py3-none-any.whl.metadata (498 bytes)\n",
            "Collecting progressbar (from speech_to_text)\n",
            "  Using cached progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click==6.7 (from speech_to_text)\n",
            "  Using cached click-6.7-py2.py3-none-any.whl.metadata (424 bytes)\n",
            "Collecting watson-developer-cloud==0.25.1 (from speech_to_text)\n",
            "  Using cached watson-developer-cloud-0.25.1.tar.gz (59 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==3.12 (from speech_to_text)\n",
            "  Using cached PyYAML-3.12.zip (375 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2bvXWvn4km8",
        "outputId": "0178d7fc-7bf6-42a7-f4b3-dfd488d59161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Speech to text and text to Speech: PythonGeeks\n",
        "#import packages\n",
        "from gtts import gTTS, lang\n",
        "import os\n",
        "from tkinter import *\n",
        "from tkinter import messagebox\n",
        "import speech_recognition as sr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "x8igxogN4J_N",
        "outputId": "599a7a3a-db4d-4408-cf3c-3f2242fd4b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'speech_recognition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-570d7a69b6a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdsPnfd_4J8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#define functions\n",
        "#text to speech conversion\n",
        "def text_to_speech():\n",
        "        #read inputs given by user\n",
        "        text = text_entry.get(\"1.0\",\"end-1c\")\n",
        "        language = accent_entry.get()\n",
        "        #Check if the user submitted inputs\n",
        "        if (len(text)<=1) | (len(language)<=0):\n",
        "                messagebox.showerror(message=\"Enter required details\")\n",
        "                return\n",
        "        #Using the inputs, convert the text to speech\n",
        "        speech = gTTS(text = text, lang = language, slow = False)\n",
        "        #save the speech to an MP3 file\n",
        "        speech.save(\"text.mp3\")\n",
        "        #Play the file usinf mpg123 in linux and start in windows\n",
        "        os.system(\"mpg123 \"+\"text.mp3\")\n",
        "\n",
        "#List the supported languages and their keys\n",
        "def list_languages():\n",
        "        #access languages and access codes using lang.tts_langs()\n",
        "        messagebox.showinfo(message=list(lang.tts_langs().items()))\n",
        "\n",
        "#speech to text conversion\n",
        "def speech_to_text():\n",
        "\n",
        "        #Initialise the recognizer class\n",
        "        recorder = sr.Recognizer()\n",
        "        try:\n",
        "                duration =int(duration_entry.get())\n",
        "        except:\n",
        "                messagebox.showerror(message=\"Enter the duration\")\n",
        "                return\n",
        "        #use the microphone\n",
        "        messagebox.showinfo(message=\"Speak into the microphone and wait after finishing the recording\")\n",
        "        with sr.Microphone() as mic:\n",
        "                #Prompt the user to record\n",
        "                #Record audio from the user\n",
        "                recorder.adjust_for_ambient_noise(mic)\n",
        "                audio_input = recorder.listen(mic, duration=duration)\n",
        "                try:                        #Convert to text\n",
        "                        text_output =recorder.recognize_google(audio_input)\n",
        "                        #Display the output\n",
        "                        messagebox.showinfo(message=\"You said:\\n \"+text_output)\n",
        "                except:\n",
        "                         messagebox.showerror(message=\"Couldn't process the audio input.\")\n",
        "\n",
        "#Invoke call to class to view a window\n",
        "window = Tk()\n",
        "#Set dimensions of window and title\n",
        "window.geometry(\"500x300\")\n",
        "window.title(\"Convert Speech to text and text to Speech: PythonGeeks\")\n",
        "title_label = Label(window, text=\"Convert Speech to text and text to Speech: PythonGeeks\").pack()\n",
        "#Read inputs\n",
        "#text_to_speech input\n",
        "text_label = Label(window, text=\"Text:\").place(x=10,y=20)\n",
        "text_entry = Text(window, width=30,height=5)\n",
        "text_entry.place(x=80,y=20)\n",
        "#Accent input\n",
        "accent_label = Label(window, text=\"Accent:\").place(x=10,y=110)\n",
        "accent_entry = Entry(window,  width=26)\n",
        "accent_entry.place(x=80,y=110)\n",
        "#Duration input\n",
        "duration_label = Label(window, text=\"Duration:\").place(x=10,y=140)\n",
        "duration_entry = Entry(window,  width=26)\n",
        "duration_entry.place(x=80,y=140)\n",
        "\n",
        "#Perform the functions\n",
        "button1 = Button(window,text='List languages', bg = 'Turquoise',fg='Red',command=list_languages).place(x=10,y=190)\n",
        "button2 = Button(window,text='Convert Text to Speech', bg = 'Turquoise',fg='Red',command=text_to_speech).place(x=130,y=190)\n",
        "button3 = Button(window,text='Convert Speech to Text', bg = 'Turquoise',fg='Red',command=speech_to_text).place(x=305,y=190)\n",
        "\n",
        "#close the app\n",
        "window.mainloop()\n"
      ],
      "metadata": {
        "id": "xzj1HMCk4Frc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}